# ğŸ‘ï¸ BogotÃ¡ Watcher

**BogotÃ¡ Watcher** es un sistema inteligente que detecta posibles riesgos en videos relacionados con el entorno urbano, con especial atenciÃ³n en transporte pÃºblico como TransMilenio.

Detecta automÃ¡ticamente situaciones como:

- Robos
- Inundaciones
- TrancÃ³n (congestiÃ³n vehicular)
- Aglomeraciones

El sistema usa redes neuronales profundas para analizar videos reales y generar alertas automÃ¡ticas.

---

**Repositorio:** https://github.com/CamilaG2/Bogota-Watch

---

## ğŸ§  Â¿QuÃ© hace este proyecto?

1. Clasifica escenas peligrosas usando un modelo **MobileNetV2**.
2. Detecta personas con **YOLOv8** para identificar aglomeraciones.
3. Combina ambas tareas para validar coincidencias y generar alertas.
4. Presenta resultados de forma visual usando **Streamlit**.

---

## ğŸ—‚ï¸ Estructura del proyecto
```
BogotaWatcher/
â”œâ”€â”€ app.py                  # Streamlit App para procesar un solo vÃ­deo
â”œâ”€â”€ run_pipeline.py         # Script principal que orquesta todo el pipeline
â”œâ”€â”€ requirements.txt        # Dependencias del proyecto
â”œâ”€â”€ README.md               # Este archivo
â”œâ”€â”€ modelo_clasificador.h5  # Este se crea al correr el archivo classify.py
â”œâ”€â”€ yolov8n.pt
â”‚
â”œâ”€â”€ data/                   # Carpeta de datos generados
â”‚   â”œâ”€â”€ raw/                # VÃ­deos descargados (.mp4)
â”‚   â”œâ”€â”€ frames/             # Frames extraÃ­dos (por video)
â”‚   â”œâ”€â”€ detecciones/        # ImÃ¡genes con detecciones superpuestas
â”‚   â””â”€â”€ clasificador/       # En esta carpeta se encontrarÃ¡ una clasificacion inicial reliazada
â”‚       â”œâ”€â”€ aglomeracion/
â”‚       â”œâ”€â”€ inundacion/
â”‚       â”œâ”€â”€ robo/
â”‚       â”œâ”€â”€ trancon/
â”‚
â””â”€â”€ src/                    # MÃ³dulos fuente
    â”œâ”€â”€ download.py         # Descargar vÃ­deos y lista `urls`
    â”œâ”€â”€ frames.py           # Extraer frames desde MP4
    â”œâ”€â”€ detector.py         # Detectar objetos con Ultralytics YOLO
    â”œâ”€â”€ alerts.py           # Cargar modelo TF y generar alertas
    â”œâ”€â”€ comparar_alertas.py # Comparar detecciones vs. clasificador
    â””â”€â”€ classify.py         # Entrenamiento del clasificador MobileNetV2
```

Se recomienda crear una carpeta llamada data y dentro de ella una llamada raw, esto con el objetivo de guardar lo generado en el archivo download.py y otra llamada frames para guardar lo generado en el archivo frames.py. Adicionalmente, para poder entrenar bien el modelo se recomienda usar la carpeta clasificador ya que en esta se encuentran 4 carpetas que contienen la base para entrenar el modelo.

---

## ğŸ§¾ Â¿CÃ³mo se puede usar?
| Script          | Herramienta | Ideal para         |
| --------------- | ----------- | ------------------ |
| `app.py`        | Streamlit   | EjecuciÃ³n local ğŸ“ |

---

## ğŸ› ï¸ Â¿CÃ³mo correr bien el proyecto?

1. Crea y activa un entorno virtual
```bash
# 1. Crear y activar venv
python -m venv venv
# macOS/Linux:
source .venv/bin/activate  
# Windows PowerShell:
venv\Scripts\activate    
# 2. Instalar dependencias  
pip install -r requirements.txt
# 3. Entrenar clasificador
python -m src.classify
# 4. Ejecutar pipeline completo
python run_pipeline.py
# 5. Levantar Streamlit
streamlit run app.py
```
   Si hay un error al activar el entorno, sigue estos pasos:
   ```bash
    Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass
    venv\Scripts\activate      # En Windows
    pip install -r requirements.txt
    python -m src.classify
    python run_pipeline.py
    streamlit run app.py
   ```
---

## ğŸ”„ Flujo del proyecto

Este es el orden en el que se ejecuta el sistema completo desde cero:

1. **Entrenar el clasificador** con las carpetas del dataset personalizado  
    Por fines prÃ¡cticos, se debe primero correr el clasificador para que el run_pipeline.py funcione de manera correcta
   Se genera el archivo `modelo_clasificador.h5`.

2. **Descargar videos** desde TikTok  
   Esto guarda los `.mp4` en `data/raw/`.

3. **Extraer frames** de los videos descargados  
   Los frames se guardan en `data/frames/`.

4. **Detectar personas con YOLOv8** en los frames   
   Se guardan imÃ¡genes con detecciones en `data/detecciones/`.

5. **Comparar resultados** de ambos modelos  
   Esto imprime coincidencias entre ambos enfoques.

6. **EjecuciÃ³n** Para tener una visiÃ³n mÃ¡s clara de lo que realiza el proyecto, al correr el archivo de app.py se abrirÃ¡ una url en donde se podrÃ¡n cargar los videos que se quieren analizar.

---

## ğŸ“‹ Dependencias

| LibrerÃ­a                  | Â¿Para quÃ© se usa?                                            |
| --------------------------|------------------------------------------------------------- |
| `yt-dlp>=2023.11.29`      | Para descargar vÃ­deos de TikTok y otras plataformas          |
| `tensorflow>=2.11.0`      | Para cargar y ejecutar el clasificador MobileNetV2 (.h5)     |
| `numpy>=1.21.0`           | Para cÃ¡lculos numÃ©ricos y manipulaciÃ³n de arrays             |
| `Pillow>=8.3.2`           | Para cargar, redimensionar y procesar imÃ¡genes               |
| `h5py>=3.1.0`             | Para leer y escribir archivos de modelo en formato HDF5 (.h5)|
| `ultralytics>=8.0.0`      | Para detecciÃ³n de personas con YOLOv8                        |
| `opencv-python>=4.5.3.56` | Para extraer frames de vÃ­deos y operar sobre imÃ¡genes        |
| `streamlit>=1.14.0`       | Para desplegar una interfaz web local y probar la aplicaciÃ³n |


---

## ğŸ“¸ CrÃ©ditos y dataset
Los videos utilizados fueron descargados desde cuentas pÃºblicas de TikTok enfocadas en noticias y seguridad en BogotÃ¡. Las imÃ¡genes extraÃ­das se agruparon en clases para crear un dataset personalizado.

---

## ğŸ“¬ AutorÃ­a
Camila Garcia \\
Universidad del Rosario

