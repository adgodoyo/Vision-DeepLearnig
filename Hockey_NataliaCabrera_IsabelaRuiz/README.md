
# ğŸ’ Proyecto Final: Sistema de VisiÃ³n Computacional para AnÃ¡lisis de Seguridad y Jugadas en Hockey

### Isabela Ruiz - Natalia Cabrera

---

## 1. ğŸ§© Resumen del problema y su impacto social

El hockey en linea  es un deporte de alto impacto fÃ­sico. Los jugadores se enfrentan a velocidades altas, superficies duras, y contacto frecuente con otros jugadores o el puck. A pesar de la exigencia reglamentaria del uso de casco y guantes, en contextos escolares o ligas menores muchas veces esta protecciÃ³n no se usa correctamente, o no se verifica.

Este proyecto busca **mejorar la seguridad y el monitoreo automatizado** de los partidos, a travÃ©s de una herramienta que:

- Detecta y sigue jugadores en video automÃ¡ticamente.
- Verifica si cada jugador usa casco y guantes.
- Clasifica jugadas clave como goles, tiros o pases.
- Genera un video final anotado con IDs, equipo de protecciÃ³n y alertas visuales.

### ğŸ’¡ Enfoque social:
Este sistema tiene como objetivo contribuir a la prevenciÃ³n de lesiones y a la formaciÃ³n de una cultura de seguridad en el deporte. Es aplicable a ligas juveniles, escuelas, torneos aficionados o prÃ¡cticas profesionales, promoviendo buenas prÃ¡cticas y reduciendo el trabajo manual de anÃ¡lisis de grabaciones.

---

## 2. ğŸ§  DescripciÃ³n de la arquitectura y desarrollo por fases

El sistema fue desarrollado en **cuatro fases principales**, todas con modelos entrenados y evaluados de forma independiente, y luego integradas en un pipeline robusto:

### ğŸ”¹ Fase 1: DetecciÃ³n de jugadores y puck

- **Modelo:** YOLOv8 (versiÃ³n pequeÃ±a) entrenado desde cero con imÃ¡genes etiquetadas por el grupo.
- **Desarrollo:** Se construyÃ³ un dataset balanceado con anotaciones YOLO, se entrenÃ³ por 30 Ã©pocas y se evaluÃ³ con mAP@0.5.
- **Resultado:** El modelo detecta correctamente jugadores en la mayorÃ­a de los frames, incluso con movimiento o cambios de cÃ¡mara.
- **AplicaciÃ³n:** Bounding boxes sobre cada jugador y puck en los videos.

### ğŸ”¹ Fase 2: Tracking de jugadores

- **TÃ©cnica:** DeepSORT (algoritmo de tracking multiobjeto basado en detecciÃ³n + movimiento).
- **Desarrollo:** Se adaptÃ³ el cÃ³digo de SORT para integrarse con las predicciones de YOLOv8 en cada frame.
- **Resultado:** Se asignan IDs Ãºnicos a cada jugador, visibles durante todo el video.
- **VisualizaciÃ³n:** Mapa de calor de trayectorias, conteo por ID, continuidad temporal.

### ğŸ”¹ Fase 3: ClasificaciÃ³n de jugadas

- **Modelo:** Red neuronal simple entrenada sobre clips de video (2â€“3 segundos) clasificados como `gol`, `tiro`, `pase`.
- **Desarrollo:** Se dividieron los videos, se etiquetaron manualmente, se entrenÃ³ la red y se integrÃ³ un clasificador por clip.
- **Resultado:** Jugadas clave son clasificadas con buena precisiÃ³n (>85%) y anotadas en el video.

### ğŸ”¹ Fase 4: VerificaciÃ³n del equipo de protecciÃ³n

- **Modelos:** Dos clasificadores ResNet18 reentrenados para:
  - Casco vs. sin casco.
  - Guantes vs. sin guantes.
- **Desarrollo:** Se creÃ³ un dataset con imÃ¡genes recortadas de jugadores, se entrenaron los clasificadores en PyTorch.
- **Resultado:** El sistema detecta visualmente si el jugador cumple con la seguridad.
- **VisualizaciÃ³n:** Etiquetas âœ” o ğŸš« sobre cada jugador detectado.

---

## 3. ğŸ—‚ï¸ Detalle de los datasets

| Dataset                      | Tipo        | Fuente                | DescripciÃ³n                                                |
|-----------------------------|-------------|------------------------|------------------------------------------------------------|
| DetecciÃ³n jugadores/puck    | Propio      | Etiquetado manual      | ImÃ¡genes de partidos reales etiquetadas con formato YOLO   |
| Seguimiento (tracking)      | Derivado    | A partir de detecciÃ³n  | Videos procesados con YOLO + DeepSORT                      |
| ClasificaciÃ³n de jugadas    | Propio      | Videos divididos       | Clips de 2â€“3 segundos anotados manualmente                 |
| Casco y guantes             | Propio      | Dataset recolectado    | ImÃ¡genes clasificadas manualmente por tipo de protecciÃ³n   |

- Archivos omitidos por limitaciones de GitHub

Este proyecto utiliza mÃ¡s de 300 imÃ¡genes clasificadas y mÃ¡s de 70 clips de video para entrenamiento, validaciÃ³n y pruebas en las distintas fases (detecciÃ³n, clasificaciÃ³n de jugadas, y verificaciÃ³n de equipo de protecciÃ³n). Sin embargo, por restricciones de GitHub:

No se incluyeron todos los archivos multimedia en este repositorio.

En particular, no se subieron los siguientes:

- Videos completos del dataset (clips de jugadas).

- ImÃ¡genes clasificadas para casco y guantes (mÃ¡s de 300 en total).

- ImÃ¡genes de validaciÃ³n 

---

## 4. ğŸ“ˆ MÃ©tricas y resultados

| Tarea                        | Modelo         | MÃ©trica clave                | Resultado aproximado |
|-----------------------------|----------------|------------------------------|-----------------------|
| DetecciÃ³n de jugadores      | YOLOv8         | mAP@0.5                      | ~91%                  |
| Seguimiento (tracking)      | DeepSORT       | IDF1                         | Alta consistencia     |
| ClasificaciÃ³n de jugadas    | Red personalizada | Accuracy en validaciÃ³n    | ~85%                  |
| Casco / Guantes             | ResNet18       | Accuracy por clase           | >90%                  |

---

## ğŸš€ Â¿CÃ³mo ejecutar el pipeline en Google Colab?

### Estructura esperada:

```
/content/
â”œâ”€â”€ run_pipeline.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ data/test.mp4
â”œâ”€â”€ models/best.pt
â”œâ”€â”€ models/modelo_casco.pth
â”œâ”€â”€ models/modelo_guantes.pth
â”œâ”€â”€ src/sort.py
```

### Pasos:

1. Instala dependencias:

```bash
!pip install -r requirements.txt
```

2. Ejecuta:

```bash
!python run_pipeline.py
```

3. Resultado por frame:

```bash
ğŸŸ¦ Frame 12:
ğŸ¯ Detecciones: 2
   ğŸ§ ID 0 â†’ Casco: âœ” | Guantes: âœ”
   ğŸ§ ID 1 â†’ Casco: âŒ | Guantes: âœ”
```

### âœ… Ejemplo real de salida final:

```
======================================
ğŸ“Š RESUMEN GENERAL DEL VIDEO
======================================
ğŸ”¢ Jugadores detectados (IDs): [0, 1, 2, ..., 502]
ğŸš¨ Jugadores sin casco: [0, 1, 2, 6, 8, ..., 491]
ğŸš¨ Jugadores sin guantes: [7, 9, 47, ..., 491]

ğŸ“¥ Descargando video procesado...
```

---

## 5. ğŸ§ª Lecciones aprendidas y trabajo futuro

### Lecciones aprendidas:

- Entrenar con tus propios datos requiere tiempo pero mejora la personalizaciÃ³n.
- La modularidad (fases separadas) permite depurar fÃ¡cilmente errores.
- La integraciÃ³n de detecciÃ³n, seguimiento y clasificaciÃ³n produce una soluciÃ³n completa y visualmente clara.

### Trabajo futuro:

- Agregar segmentaciÃ³n de cancha para analizar zonas activas.
- Detectar eventos anÃ³malos como caÃ­das, peleas o lesiones.
- Mejorar clasificaciÃ³n de jugadas con modelos temporales (CNN+LSTM).
- Desplegar en tiempo real con Jetson Nano o Raspberry Pi.
