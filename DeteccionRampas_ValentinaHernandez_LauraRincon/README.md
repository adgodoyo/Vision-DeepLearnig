
# Proyecto Final: IdentificaciÃ³n automatizada de rampas urbanas para movilidad inclusiva

**Por: Valentina HernÃ¡ndez Quintana y Laura Alejandra RincÃ³n CastaÃ±o**

---

## ğŸ§© Problema y su impacto social

En las ciudades modernas, garantizar la movilidad inclusiva es un desafÃ­o pendiente. A pesar de que existen normas sobre accesibilidad universal y diseÃ±o de infraestructura adaptada, en la prÃ¡ctica muchas calles no cuentan con rampas peatonales o su ubicaciÃ³n no estÃ¡n documentadas.

Las rampas son esenciales para personas con discapacidad motriz, adultos mayores, usuarios de sillas de ruedas, personas con cochecitos, entre otros. Sin embargo, actualmente no hay mecanismos eficientes ni automatizados para identificar, mapear y monitorear estas estructuras en el espacio urbano.

Este proyecto propone una soluciÃ³n basada en visiÃ³n por computador que permite detectar y segmentar automÃ¡ticamente rampas peatonales en imÃ¡genes del entorno urbano. Esta informaciÃ³n se convierte en datos georreferenciados que pueden ser publicados, visualizados y usados por gobiernos locales, organizaciones de accesibilidad, desarrolladores de apps inclusivas o sistemas de navegaciÃ³n.

El impacto social puede verse en:

âœ… Promueve la movilidad inclusiva, permitiendo planificar y verificar infraestructura para todos.

âœ… Reduce brechas de informaciÃ³n sobre la localizaciÃ³n de las rampas urbanas.

âœ… Automatiza procesos que hoy son manuales y costosos, como los censos urbanos de accesibilidad.

âœ… Contribuye a los Objetivos de Desarrollo Sostenible (ODS), especialmente el ODS 11: Ciudades y comunidades sostenibles.

---

## ğŸ› ï¸ DescripciÃ³n de la arquitectura y decisiones de diseÃ±o

La soluciÃ³n estÃ¡ compuesta por un pipeline que combina detecciÃ³n y segmentaciÃ³n de rampas, georreferenciaciÃ³n de los resultados y publicaciÃ³n en la nube mediante GitHub Pages. A continuaciÃ³n, se detallan los componentes clave:

### ğŸ” Modelo de detecciÃ³n

Se utilizÃ³ **YOLOv11n** para identificar la presencia de rampas en imÃ¡genes urbanas. Aunque el modelo estÃ¡ preentrenado en COCO, se realizÃ³ fine-tuning con un dataset propio utilizando Roboflow y configuraciones personalizadas.

### âœ‚ï¸ Modelo de segmentaciÃ³n

Se implementÃ³ **YOLOv11n-seg** para obtener una mÃ¡scara precisa de la rampa en cada imagen. TambiÃ©n se realizÃ³ entrenamiento sobre datos anotados manualmente para mejorar el desempeÃ±o en condiciones locales.

### ğŸ§­ GeorreferenciaciÃ³n

A partir de un archivo `.csv` con coordenadas de latitud y longitud por imagen, se tradujeron las posiciones de detecciÃ³n (en pÃ­xeles) a coordenadas geogrÃ¡ficas, estimando asÃ­ la ubicaciÃ³n real de cada rampa detectada.

### â˜ï¸ PublicaciÃ³n web

El resultado se guarda en un archivo `.csv` y se sube automÃ¡ticamente a un repositorio de GitHub, desde donde se puede visualizar de manera interactiva a travÃ©s de **GitHub Pages**.

---

## ğŸ—ƒï¸ Estructura del pipeline

1. InstalaciÃ³n de dependencias (`ultralytics`, `roboflow`, `opencv`, `matplotlib`, etc.)
2. Descarga de datasets desde Roboflow.
3. Entrenamiento de modelos YOLO (detecciÃ³n y segmentaciÃ³n).
4. Inferencia sobre imÃ¡genes de prueba.
5. ConversiÃ³n de coordenadas pÃ­xel â†’ geogrÃ¡ficas.
6. VisualizaciÃ³n con `matplotlib`.
7. ExportaciÃ³n a CSV y subida a GitHub.
8. VisualizaciÃ³n en: [Mapa de rampas](https://laurar287.github.io/Mapa-rampas/)

---

## ğŸ§ª Datasets utilizados

- **Propios**: ImÃ¡genes recolectadas en entornos urbanos reales.
- **Roboflow**: Uso de la plataforma para anotaciÃ³n, gestiÃ³n y descarga de los datasets en formato compatible con YOLOv11.

Los datasets fueron preparados siguiendo la estructura requerida por Ultralytics:

```
dataset/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ train/
â”‚   â””â”€â”€ val/
â”œâ”€â”€ labels/
â”‚   â”œâ”€â”€ train/
â”‚   â””â”€â”€ val/
```

---

## ğŸ“ˆ MÃ©tricas y resultados

- **DetecciÃ³n**: Se alcanzÃ³ una precisiÃ³n satisfactoria con `mAP@0.5 â‰ˆ 0.47` y `mAP@0.5:0.95 â‰ˆ 0.34` en el dataset personalizado.
- **SegmentaciÃ³n**: Se lograron resultados Ãºtiles para superponer mÃ¡scaras que ayudan a validar y visualizar la posiciÃ³n precisa de las rampas.
- **GeorreferenciaciÃ³n**: La conversiÃ³n de pÃ­xeles a coordenadas funcionÃ³ con buena aproximaciÃ³n para visualizaciÃ³n en mapas urbanos.

---

## ğŸ§  Lecciones aprendidas y mejoras futuras

- La combinaciÃ³n de modelos de segmentaciÃ³n y detecciÃ³n puede fortalecer la precisiÃ³n del sistema.
- Es fundamental disponer de datasets de mayor tamaÃ±o y variedad para mejorar el rendimiento de los modelos.
- El proceso de anotaciÃ³n manual en plataformas como CVAT o Roboflow requiere tiempo, pero mejora la calidad del entrenamiento.
- Se podrÃ­an integrar tÃ©cnicas de aumento de datos y mapas base tipo Leaflet o Folium para mejorar la visualizaciÃ³n geogrÃ¡fica.
- Implementar una app mÃ³vil que consuma este servicio permitirÃ­a escalar el impacto del proyecto.

---

## ğŸ“¦ Requisitos (requirements.txt)

```txt
ultralytics==8.0.20
roboflow==1.1.17
matplotlib==3.7.1
PyGithub==1.59.0
opencv-python-headless==4.7.0.72
pandas==1.5.3
numpy==1.22.4
requests==2.28.2
```

---

## ğŸ“š Referencias

1. Ultralytics YOLO Docs: https://docs.ultralytics.com/
2. Roboflow Docs: https://docs.roboflow.com/
3. GitHub PyGithub Docs: https://pygithub.readthedocs.io/
