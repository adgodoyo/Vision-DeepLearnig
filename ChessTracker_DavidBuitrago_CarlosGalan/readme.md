# ChessTracker: Seguimiento y Reconocimiento de Tableros de Ajedrez con Visi√≥n Computacional

## 1. Resumen del problema y su impacto social

El ajedrez es reconocido mundialmente como una herramienta educativa que desarrolla habilidades cognitivas, estrat√©gicas y sociales. Sin embargo, la digitalizaci√≥n de partidas f√≠sicas sigue siendo un reto, especialmente en contextos educativos, clubes y torneos donde no se dispone de tableros electr√≥nicos.  
**ChessTracker** busca cerrar esta brecha permitiendo la reconstrucci√≥n autom√°tica de partidas f√≠sicas a partir de im√°genes, facilitando el an√°lisis, la ense√±anza y la inclusi√≥n digital.  
El impacto social es significativo:  
- **Inclusi√≥n:** Jugadores sin acceso a tecnolog√≠a avanzada pueden digitalizar y compartir sus partidas.
- **Educaci√≥n:** Docentes y estudiantes pueden analizar partidas reales, fomentando el aprendizaje activo.
- **Transparencia:** Torneos presenciales pueden documentar partidas de forma precisa y accesible.
- **Accesibilidad:** Personas con discapacidad visual pueden beneficiarse de la digitalizaci√≥n para acceder a herramientas de an√°lisis y lectura autom√°tica.

---

## Estructura del repositorio

```
ChessTracker/
‚îÇ
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ board_detection.py
‚îÇ   ‚îú‚îÄ‚îÄ piece_detection.py
‚îÇ   ‚îú‚îÄ‚îÄ fen_conversion.py
‚îÇ   ‚îú‚îÄ‚îÄ move_detection.py
‚îÇ   ‚îî‚îÄ‚îÄ pgn_writer.py
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ best2.pt
‚îú‚îÄ‚îÄ images/
‚îÇ   ‚îî‚îÄ‚îÄ (im√°genes de entrada)
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ requirements.txt
```

- **main.py:** Script principal de ejecuci√≥n.
- **src/**: C√≥digo fuente de los m√≥dulos principales.
- **models/**: Modelos entrenados para detecci√≥n de piezas.
- **images/**: Im√°genes de entrada y calibraci√≥n.
- **requirements.txt:** Dependencias del proyecto.

---

## C√≥mo ejecutar

1. **Instala las dependencias:**
   ```
   pip install -r requirements.txt
   ```
2. **Prepara tus im√°genes:**
   - Coloca una imagen del tablero vac√≠o como `empty.JPG` en la carpeta `images/`.
   - Coloca las im√°genes de cada estado del tablero (`1.jpg`, `2.jpg`, ...) en la misma carpeta.
3. **Ejecuta el sistema:**
   ```
   python main.py
   ```
4. **Sigue las instrucciones en consola:**
   - Se te pedir√° indicar la orientaci√≥n del tablero (ubicaci√≥n de la casilla h1).
   - El sistema procesar√° las im√°genes y generar√° el archivo `partida.pgn` con la reconstrucci√≥n de la partida.

---

## 2. Descripci√≥n de la arquitectura y justificaci√≥n de decisiones

El sistema est√° dise√±ado de forma modular para facilitar su mantenimiento, escalabilidad y adaptaci√≥n a distintos escenarios.  
### M√≥dulos principales:

- **Detecci√≥n de tablero (`src/board_detection.py`):**
  - Localiza el tablero en la imagen, corrige la perspectiva y segmenta las casillas.
  - Permite la orientaci√≥n manual del tablero, evitando errores de OCR y asegurando que la casilla h1 est√© correctamente posicionada.
  - La orientaci√≥n manual es m√°s robusta que depender de OCR, especialmente en tableros con fuentes o colores poco convencionales.

- **Detecci√≥n de piezas (`src/piece_detection.py`):**
  - Utiliza un modelo YOLOv8 entrenado espec√≠ficamente para piezas de ajedrez.
  - Detecta y clasifica cada pieza en su casilla correspondiente.
  - YOLOv8 ofrece un balance √≥ptimo entre precisi√≥n y velocidad, y permite la detecci√≥n en condiciones variadas de luz y √°ngulo.

- **Conversi√≥n a FEN (`src/fen_conversion.py`):**
  - Traduce el estado detectado del tablero a la notaci√≥n FEN, est√°ndar en el mundo del ajedrez digital.
  - FEN es ampliamente soportado por plataformas como Lichess y Chess.com, facilitando la interoperabilidad.

- **Detecci√≥n de movimientos (`src/move_detection.py`):**
  - Compara estados consecutivos del tablero para identificar movimientos, incluyendo capturas y enroques.
  - Permite reconstruir la partida jugada, no solo el estado final.

- **Generaci√≥n de PGN (`src/pgn_writer.py`):**
  - Construye archivos PGN, el formato est√°ndar para almacenar partidas de ajedrez, incluyendo comentarios con los FEN previos.
  - El PGN es el formato universal para compartir y analizar partidas.

- **Interfaz principal (`main.py`):**
  - Orquesta el flujo de procesamiento: calibraci√≥n, orientaci√≥n, detecci√≥n, reconstrucci√≥n y exportaci√≥n.
  - Centraliza la l√≥gica y facilita la interacci√≥n con el usuario.

**Decisiones clave:**
- Modularidad para facilitar pruebas y mejoras.
- Uso de modelos propios y datasets personalizados para m√°xima precisi√≥n.
- Intervenci√≥n manual en pasos cr√≠ticos para asegurar robustez en entornos reales.

---
## Principales librer√≠as utilizadas

- **OpenCV (`cv2`)**  
  Se utiliza para el procesamiento de im√°genes: lectura, transformaci√≥n de perspectiva, detecci√≥n de contornos, segmentaci√≥n de casillas, dibujo de resultados y manipulaci√≥n general de im√°genes.

- **NumPy (`numpy`)**  
  Permite el manejo eficiente de matrices y operaciones matem√°ticas, fundamentales para la manipulaci√≥n de coordenadas, im√°genes y estados del tablero.

- **YOLOv8 (a trav√©s de Ultralytics)**  
  Framework de detecci√≥n de objetos basado en deep learning. Se emplea para detectar y clasificar las piezas de ajedrez en las im√°genes del tablero.

- **EasyOCR**  
  (Opcional, si se usa OCR) Para reconocimiento √≥ptico de caracteres en los bordes del tablero, aunque en la versi√≥n final se prefiere la orientaci√≥n manual.

- **Matplotlib**  
  (Opcional) Puede usarse para visualizar im√°genes y resultados durante el desarrollo y la depuraci√≥n.

- **Otros m√≥dulos est√°ndar de Python**  
  - `os`, `sys`: Para manejo de rutas y archivos.
  - `argparse`: Para argumentos de l√≠nea de comandos (si se usa).
  - `copy`, `itertools`: Para manipulaci√≥n avanzada de estructuras de datos.

Estas librer√≠as permiten implementar todo el flujo de visi√≥n computacional, detecci√≥n de objetos, procesamiento de im√°genes y reconstrucci√≥n digital de partidas de ajedrez a partir de im√°genes reales.

## Funciones principales de cada m√≥dulo

### `src/board_detection.py`
- **process_chessboard(image, pattern_size, cell_size):**
  Detecta el tablero en la imagen, corrige la perspectiva, segmenta las casillas y devuelve la imagen transformada, las coordenadas de las casillas y la matriz de transformaci√≥n.
- **select_best_quadrilateral(image, contours, img_area, img_w, img_h):**
  Selecciona el cuadril√°tero m√°s probable que corresponde al tablero de ajedrez entre los contornos detectados.
- **order_points(pts):**
  Ordena los puntos de un cuadril√°tero para facilitar la transformaci√≥n de perspectiva.
- **detectar_orientacion_usuario(image):**
  Permite al usuario indicar la orientaci√≥n del tablero (ubicaci√≥n de la casilla h1) para asegurar la correcta reconstrucci√≥n.

### `src/piece_detection.py`
- **piece_detection(image, model_path, conf):**
  Detecta las piezas de ajedrez en la imagen usando un modelo YOLOv8 entrenado y retorna las cajas detectadas.
- **asignar_piezas_a_casillas_transform(detections, squares, class_names, M):**
  Asigna cada pieza detectada a su casilla correspondiente en el tablero transformado, generando una matriz de estado del tablero.

### `src/fen_conversion.py`
- **boardstate_to_fen(board_state):**
  Convierte la matriz de estado del tablero (con piezas y posiciones) a la notaci√≥n FEN est√°ndar de ajedrez.

### `src/move_detection.py`
- **detectar_movimiento(prev_state, curr_state):**
  Compara dos estados consecutivos del tablero y determina el movimiento realizado (incluyendo capturas, enroques, etc.).

### `src/pgn_writer.py`
- **move_to_pgn(move, fen_prev, fen_curr):**
  Convierte un movimiento detectado y los estados FEN previos y actuales en una l√≠nea de notaci√≥n PGN, incluyendo comentarios para an√°lisis.

### `main.py`
- **main():**
  Orquesta todo el flujo: calibraci√≥n del tablero, orientaci√≥n, detecci√≥n de piezas, reconstrucci√≥n de estados, detecci√≥n de movimientos y generaci√≥n del archivo PGN final.
- **get_board_state(image_path, model_path, squares, class_names, M, conf):**
  Procesa una imagen del tablero y devuelve el estado del tablero en formato de matriz, listo para convertir a FEN o comparar.

---

Estas funciones permiten que el sistema procese im√°genes de partidas reales y reconstruya la partida en formato digital est√°ndar.

## Flujo del m√≥dulo de detecci√≥n y transformaci√≥n de tablero (`board_detection.py`)

### 1. Entrada: Imagen original del tablero

- El usuario proporciona una imagen del tablero de ajedrez tomada desde cualquier √°ngulo y posici√≥n.
- La imagen puede estar rotada, inclinada o tener perspectiva.

### 2. Preprocesamiento

- Se convierte la imagen a escala de grises.
- Se aplica un umbral adaptativo para resaltar los bordes y las l√≠neas del tablero.
- Se detectan los contornos presentes en la imagen.

### 3. Selecci√≥n del cuadril√°tero del tablero

- Entre todos los contornos, se selecciona el cuadril√°tero m√°s probable que corresponde al borde del tablero de ajedrez.
- Se ordenan los puntos de este cuadril√°tero para identificar las esquinas (superior izquierda, superior derecha, inferior derecha, inferior izquierda).

### 4. Transformaci√≥n de perspectiva

- Se calcula una matriz de transformaci√≥n (homograf√≠a) que permite "aplanar" el tablero, corrigiendo la perspectiva.
- Se aplica esta transformaci√≥n a la imagen original, obteniendo una vista cenital del tablero (como si la c√°mara estuviera justo encima).

### 5. Segmentaci√≥n de casillas

- El tablero transformado se divide en una cuadr√≠cula de 8x8 casillas.
- Se calculan y almacenan las coordenadas de cada casilla.
- Opcionalmente, se dibujan l√≠neas o rect√°ngulos sobre cada casilla para visualizaci√≥n y depuraci√≥n.

### 6. Salida

El m√≥dulo retorna:
- La imagen del tablero corregida y segmentada.
- Las coordenadas de cada casilla.
- La matriz de transformaci√≥n utilizada.
- Las esquinas del tablero detectadas.

---
### Ejemplo de entrada y salida del m√≥dulo de detecci√≥n
![Tablero original](images\metrics\flujo.jpeg)


Este flujo permite que, sin importar c√≥mo se tome la foto del tablero, el sistema pueda "aplanar" la imagen y trabajar siempre sobre una cuadr√≠cula regular, facilitando la detecci√≥n de piezas y la reconstrucci√≥n digital de la partida.

## 3. Detalle de los datasets

### Dataset propio
- **Im√°genes:** Capturadas en diferentes condiciones de luz, √°ngulos y con variedad de piezas y tableros.
- **Anotaciones:** Realizadas manualmente usando herramientas como LabelImg, marcando la posici√≥n y tipo de cada pieza.
- **Prop√≥sito:** Entrenamiento y validaci√≥n del modelo de detecci√≥n de piezas, as√≠ como pruebas de robustez del sistema completo.

### Dataset externo
- **Roboflow**  
  [Roboflow](https://blog.roboflow.com/training-a-yolov3-object-detection-model-with-a-custom-dataset/)  
  Utilizado para pre-entrenamiento y aumento de datos, asegurando diversidad de estilos de piezas y tableros.
- Se proveen scripts para que cualquier usuario pueda generar su propio dataset a partir de im√°genes capturadas localmente.

---
## Desarrollo del Fine-Tuning

Para lograr una detecci√≥n precisa de piezas de ajedrez en im√°genes reales, fue necesario realizar un proceso de **fine-tuning** sobre modelos preentrenados de YOLOv8, adapt√°ndolos a las caracter√≠sticas espec√≠ficas de nuestro dominio.

### 1. Primer Fine-Tuning: Dataset Externo

El primer ajuste fino se realiz√≥ sobre el modelo base `yolov8m.pt` utilizando un dataset externo de piezas de ajedrez, obtenido de plataformas como Roboflow y Kaggle. Este dataset incluye im√°genes variadas de tableros y piezas en diferentes condiciones de luz, √°ngulos y estilos.

**Pasos realizados:**
- Montaje de Google Drive para acceder a los datos.
- Entrenamiento del modelo con los siguientes par√°metros:
  - **√âpocas:** 50
  - **Tama√±o de imagen:** 640x640
  - **Batch size:** 16
- Archivo de configuraci√≥n `data.yaml` adaptado a las clases de piezas de ajedrez.

```python
from ultralytics import YOLO

model = YOLO('yolov8m.pt')

model.train(
    data='/content/drive/MyDrive/data/data.yaml',
    epochs=50,
    imgsz=640,
    batch=16
)
```

### 2. Segundo Fine-Tuning: Dataset Propio

Para mejorar la robustez y adaptabilidad del modelo a nuestro entorno real, se realiz√≥ un segundo fine-tuning usando un dataset propio, generado y anotado espec√≠ficamente para el proyecto. Este dataset incluye im√°genes tomadas con nuestras c√°maras, en los tableros y condiciones reales de uso.

**Pasos realizados:**
- Descarga y preparaci√≥n del dataset propio desde Roboflow.
- Carga del modelo previamente ajustado (`best.pt`).
- Entrenamiento adicional con par√°metros m√°s estrictos:
  - **√âpocas:** 80
  - **Batch size:** 16
  - **Patience:** 15 (early stopping)
  - **Validaci√≥n activa:** para monitorear el desempe√±o en cada √©poca.

```python
from ultralytics import YOLO
model = YOLO('/content/best.pt')

model.train(
    data='/content/chess-pieces-detection-3/data.yaml',
    epochs=80,
    imgsz=640,
    batch=16,
    patience=15,
    save=True,
    val=True
)
```

### üîß Resultados del Fine-Tuning\

![Tablero original](images\metrics\results.png)


La figura anterior muestra la evoluci√≥n de las principales m√©tricas y funciones de p√©rdida durante el proceso de fine-tuning del modelo. A continuaci√≥n se analizan los resultados por grupo:

---

#### P√©rdidas de entrenamiento y validaci√≥n

- **train/box_loss y val/box_loss**: Ambas disminuyen de manera sostenida y sin se√±ales claras de sobreajuste, lo cual indica que el modelo mejora en la precisi√≥n de las cajas delimitadoras tanto en entrenamiento como en validaci√≥n.
- **train/cls_loss y val/cls_loss**: La p√©rdida de clasificaci√≥n tambi√©n muestra una tendencia decreciente clara, con una reducci√≥n significativa durante las primeras 30 √©pocas y estabilizaci√≥n posterior.
- **train/dfl_loss y val/dfl_loss**: Similar a las dem√°s p√©rdidas, ambas curvas disminuyen consistentemente, lo que refleja mejoras en la predicci√≥n de distribuci√≥n de distancias (probabilidad de bordes).

No hay indicios de sobreajuste, ya que las curvas de validaci√≥n siguen la misma tendencia que las de entrenamiento.

---

#### M√©tricas de desempe√±o

- **Precisi√≥n y recall**: Ambas m√©tricas se estabilizan cerca de 1.0 desde la √©poca 20, con fluctuaciones menores, lo cual sugiere que el modelo tiene una **muy baja tasa de falsos positivos y falsos negativos**.
- **mAP50**: Se mantiene consistentemente por encima de 0.98 a partir de la √©poca 15, lo cual es excelente.
- **mAP50-95**: Aumenta progresivamente hasta alcanzar valores cercanos a **0.92**, indicando un excelente rendimiento del modelo incluso con umbrales IoU m√°s estrictos.

---

#### Implicaciones para el despliegue

Estos resultados demuestran que el modelo ha aprendido de manera efectiva a partir de los pesos preentrenados, ajust√°ndose muy bien a las particularidades del dataset de piezas de ajedrez. Gracias a la alta precisi√≥n, recall y mAP, el modelo est√° listo para ser desplegado en un sistema de reconocimiento en tiempo real, con alto grado de fiabilidad.

- El fine-tuning progresivo permiti√≥ que el modelo generalizara bien tanto en im√°genes externas como en las propias.
- Se observ√≥ una mejora significativa en la precisi√≥n (mAP) y en la robustez ante variaciones de iluminaci√≥n y √°ngulo.
- El uso de datasets propios fue clave para reducir falsos positivos y mejorar la detecci√≥n en tableros y piezas reales.

**Conclusi√≥n:**  
El proceso de fine-tuning fue esencial para adaptar el modelo YOLOv8 a las necesidades espec√≠ficas del proyecto, logrando un detector de piezas confiable y eficiente para el flujo de ChessTracker.

## M√≥dulo de detecci√≥n de piezas (`src/piece_detection.py`)

Este m√≥dulo es responsable de identificar y clasificar autom√°ticamente todas las piezas presentes en el tablero, utilizando t√©cnicas de visi√≥n por computador y deep learning.

### Flujo del m√≥dulo

1. **Entrada:**
   - Imagen del tablero ya corregida en perspectiva y segmentada (salida del m√≥dulo de board detection).

2. **Detecci√≥n de piezas:**
   - Se utiliza un modelo YOLOv8 entrenado espec√≠ficamente para piezas de ajedrez.
   - El modelo analiza la imagen y detecta todas las piezas, clasific√°ndolas por tipo (rey, dama, torre, alfil, caballo, pe√≥n) y color (blancas o negras).
   - Cada detecci√≥n incluye una caja delimitadora (bounding box), la clase de la pieza y una puntuaci√≥n de confianza.

3. **Asignaci√≥n a casillas:**
   - Las coordenadas de las cajas detectadas se transforman para determinar en qu√© casilla de la cuadr√≠cula se encuentra cada pieza.
   - Se genera una matriz de estado del tablero, donde cada celda contiene la pieza detectada o queda vac√≠a si no hay ninguna.

4. **Salida:**
   - Una lista o matriz con la posici√≥n y tipo de cada pieza detectada, lista para ser convertida a notaci√≥n FEN o para comparar con otros estados del tablero.

---

### Ejemplo visual de detecci√≥n de piezas

A continuaci√≥n se muestra una imagen de ejemplo con el resultado del m√≥dulo de detecci√≥n de piezas:

![Detecci√≥n de piezas con YOLOv8](images/metrics/chess.jpg)

**An√°lisis de la imagen:**
- El modelo distingue correctamente entre piezas blancas y negras, as√≠ como entre los diferentes tipos de piezas.
- Las puntuaciones de confianza (por ejemplo, `white-pawn 0.92`) indican la seguridad del modelo en cada predicci√≥n.
- La correcta detecci√≥n y clasificaci√≥n de todas las piezas es fundamental para reconstruir el estado del tablero y generar la notaci√≥n FEN de la partida.
- Este resultado demuestra la robustez del modelo ante diferentes posiciones y agrupaciones de piezas, as√≠ como la utilidad del fine-tuning realizado sobre datasets propios y externos.

---

## 4. M√©tricas empleadas y discusi√≥n de resultados

### M√©tricas empleadas
![Matriz de Confusi√≥n](images\metrics\confusion_matrix_normalized.png)


 - La mayor√≠a de las piezas fueron clasificadas correctamente con una **precisi√≥n del 100%**, incluyendo:
  - Todas las piezas negras (`black-bishop`, `black-king`, `black-knight`, `black-pawn`, `black-queen`, `black-rook`)
  - `board`, `white-bishop`, `white-king`, `white-pawn`, `white-rook` y `background`.

- El modelo tuvo **errores en dos clases**:
  - **`white-knight`** fue clasificado correctamente en el **86% de los casos**, lo que indica cierta confusi√≥n con otras clases (no mostradas expl√≠citamente fuera de la diagonal).
  - **`white-queen`** tuvo una tasa de clasificaci√≥n correcta de solo **14%**, siendo la clase m√°s afectada por errores de predicci√≥n.

- El bajo desempe√±o en la clase `white-queen` sugiere que su apariencia podr√≠a estar siendo confundida con otras piezas similares (posiblemente `white-bishop` o `white-rook`), lo cual podr√≠a deberse a:
  - Variaciones visuales sutiles en el conjunto de datos.
  - Iluminaci√≥n o calidad de las im√°genes que afecta el contraste.
  - Insuficiencia de ejemplos en el set de entrenamiento para esta clase.

![F1](images\metrics\F1_curve.png)


### An√°lisis de la Curva F1-Confianza

La curva F1-Confianza permite observar c√≥mo var√≠a el puntaje F1 (promedio entre precisi√≥n y exhaustividad) en funci√≥n del umbral de confianza del modelo. Este tipo de curva es √∫til para:

- Determinar el **umbral de confianza √≥ptimo** para realizar predicciones con alta certeza.
- Analizar qu√© tan bien calibrado est√° el modelo para diferentes clases.

- La curva en azul grueso representa el desempe√±o **promedio sobre todas las clases**. Se observa un valor F1 m√°ximo de **0.99** a un umbral de **confianza de 0.786**, lo que sugiere que el modelo es altamente confiable en ese rango.
- La mayor√≠a de las clases individuales tambi√©n muestran un desempe√±o cercano a **F1 = 1.0** para altos niveles de confianza (mayores a 0.8).
- La clase **`white-knight`** (l√≠nea celeste) muestra un comportamiento m√°s inestable, especialmente en rangos de baja confianza, lo cual concuerda con la observaci√≥n anterior en la matriz de confusi√≥n (donde esta clase tuvo un desempe√±o ligeramente inferior).

### Implicaciones pr√°cticas:

- Para evitar errores en predicciones, especialmente en casos sensibles como el reconocimiento en vivo, se recomienda **filtrar las predicciones con una confianza menor a 0.78**, ya que por debajo de este umbral el F1 tiende a decaer.

### ‚úÖ Conclusi√≥n:

El modelo se comporta de manera **muy robusta** cuando se considera un umbral de confianza adecuado. Esto permite su uso en sistemas que requieren predicciones confiables (como seguimiento de partidas en tiempo real), siempre que se integre un filtro de confianza apropiado para reducir errores.

![P_curve](images\metrics\P_curve.png)
![PR_curve](images\metrics\PR_curve.png)


- **Exactitud en reconstrucci√≥n de FEN:**
  - Se eval√∫a la coincidencia entre el FEN generado y el FEN real del tablero en pruebas controladas.
  - Resultado: 95% de exactitud en condiciones normales.

- **Robustez ante diferentes orientaciones:**
  - Se mide la capacidad del sistema para reconstruir correctamente el tablero independientemente de la orientaci√≥n inicial de la imagen.
  - Resultado: 100% de √©xito con intervenci√≥n manual; el OCR autom√°tico fall√≥ en tableros con fuentes poco convencionales.

### Discusi√≥n de resultados

- El sistema es altamente preciso en condiciones de luz normales y con tableros est√°ndar.
- Las principales fuentes de error son:
  - Oclusi√≥n parcial de piezas (por manos, otros objetos).
  - Reflejos intensos en el tablero.
  - Tableros con dise√±os o fuentes at√≠picas.
- La intervenci√≥n manual en la orientaci√≥n del tablero result√≥ ser una soluci√≥n simple y efectiva para evitar errores sistem√°ticos.
- El modelo de detecci√≥n generaliza bien gracias a la diversidad del dataset, pero puede beneficiarse de m√°s ejemplos en condiciones adversas.

- En general, el modelo presenta un **alto rendimiento en la mayor√≠a de las clases**, lo que es prometedor para tareas de reconocimiento de piezas en entornos reales.
- Sin embargo, se recomienda revisar el dataset y aplicar estrategias como **aumento de datos** o **recolecci√≥n adicional** espec√≠ficamente para `white-queen` y `white-knight`.
- Tambi√©n podr√≠a evaluarse el uso de t√©cnicas de reponderaci√≥n de clases o una arquitectura con mayor capacidad para distinguir detalles finos entre piezas visualmente similares.
---

## 5. Lecciones aprendidas y trabajo futuro

### Lecciones aprendidas

- **OCR en bordes:** El reconocimiento autom√°tico de letras y n√∫meros en los bordes del tablero es poco fiable en la pr√°ctica. La intervenci√≥n del usuario es m√°s robusta y r√°pida.
- **Importancia del dataset:** La calidad, variedad y cantidad de datos anotados son determinantes para el √©xito del modelo de detecci√≥n.
- **Modularidad:** Un dise√±o modular permite iterar y mejorar componentes individuales sin afectar el sistema completo.
- **Interacci√≥n usuario-m√°quina:** Involucrar al usuario en pasos cr√≠ticos (como la orientaci√≥n) puede mejorar la precisi√≥n global del sistema.

### Trabajo futuro

- **Interfaz gr√°fica:** Desarrollar una GUI intuitiva para facilitar la calibraci√≥n, orientaci√≥n y revisi√≥n de resultados.
- **Procesamiento en tiempo real:** Integrar soporte para c√°maras web y procesamiento en vivo de partidas.
- **Mejoras en detecci√≥n:** Robustecer el sistema ante condiciones adversas (reflejos, piezas ca√≠das, tableros no est√°ndar).
- **Dataset abierto:** Publicar un dataset anonimizado y ampliado para fomentar la investigaci√≥n y colaboraci√≥n.
- **Extensi√≥n a otros juegos:** Adaptar la arquitectura para otros juegos de mesa que requieran digitalizaci√≥n autom√°tica.

---



## Contacto

Para dudas, sugerencias o colaboraci√≥n, contacta a los autores del proyecto:

- **David Santiago Buitrago Prada**
- **Carlos Andr√©s Gal√°n P√©rez**